"""Performance metrics calculation and display commands."""

import click
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.progress import Progress, BarColumn, TextColumn

from osl_cli.state.schemas import CoachState, SessionState
from osl_cli.state.manager import StateManager


@click.group(name="metrics")
@click.pass_context
def metrics_group(ctx: click.Context) -> None:
    """Calculate and display learning metrics."""
    pass


@metrics_group.command(name="show")
@click.option("--period", "-p", 
              type=click.Choice(["today", "week", "month", "all"]),
              default="week",
              help="Time period to analyze")
@click.pass_context
def show_metrics(ctx: click.Context, period: str) -> None:
    """Display comprehensive learning metrics.
    
    Shows:
    - Retrieval rates and trends
    - Card debt and throughput
    - Session consistency
    - Governance gate status
    """
    console: Console = ctx.obj['console']
    state_manager = StateManager()
    
    coach_state = state_manager.load_coach_state()
    metrics = coach_state.performance_metrics
    
    # Calculate period-specific metrics
    if period == "today":
        period_label = "Today"
        retrieval_score = metrics.avg_retrieval_7d  # Would be today's in full impl
    elif period == "week":
        period_label = "This Week"
        retrieval_score = metrics.avg_retrieval_7d
    elif period == "month":
        period_label = "This Month" 
        retrieval_score = metrics.avg_retrieval_7d  # Would calculate 30d average
    else:
        period_label = "All Time"
        retrieval_score = metrics.avg_retrieval_7d  # Would calculate all-time
    
    # Create main metrics table
    table = Table(title=f"ğŸ“Š Learning Metrics - {period_label}", show_header=True)
    table.add_column("Metric", style="cyan", width=25)
    table.add_column("Value", style="white", justify="right", width=15)
    table.add_column("Target", style="dim", justify="right", width=15)
    table.add_column("Status", justify="center", width=10)
    
    # Retrieval rate
    retrieval_status = "ğŸŸ¢" if retrieval_score >= coach_state.governance_thresholds.calibration_gate.min else "ğŸ”´"
    table.add_row(
        "Retrieval Rate",
        f"{retrieval_score:.1f}%",
        f"{coach_state.governance_thresholds.calibration_gate.min}-{coach_state.governance_thresholds.calibration_gate.max}%",
        retrieval_status
    )
    
    # Card debt
    card_debt_ratio = metrics.current_card_debt_ratio
    debt_status = "ğŸŸ¢" if card_debt_ratio <= coach_state.governance_thresholds.card_debt_multiplier.current else "ğŸ”´"
    table.add_row(
        "Card Debt Ratio",
        f"{card_debt_ratio:.1f}x",
        f"â‰¤{coach_state.governance_thresholds.card_debt_multiplier.current}x",
        debt_status
    )
    
    # Calibration accuracy
    cal_status = "ğŸŸ¢" if metrics.avg_prediction_accuracy_7d >= 70 else "ğŸŸ¡" if metrics.avg_prediction_accuracy_7d >= 50 else "ğŸ”´"
    table.add_row(
        "Calibration Accuracy",
        f"{metrics.avg_prediction_accuracy_7d:.0f}%",
        "70-90%",
        cal_status
    )
    
    # Interleaving
    interleave_status = "ğŸŸ¢" if metrics.interleaving_sessions_week >= 1 else "ğŸŸ¡"
    table.add_row(
        "Interleaving (week)",
        str(metrics.interleaving_sessions_week),
        "1-3",
        interleave_status
    )
    
    # Knowledge artifacts
    table.add_row(
        "Permanent Notes",
        str(metrics.total_permanent_notes),
        "â€”",
        "ğŸ“"
    )
    
    table.add_row(
        "Flashcards Created",
        str(metrics.total_flashcards),
        "â€”",
        "ğŸ—‚ï¸"
    )
    
    # Misconceptions
    misc_status = "ğŸŸ¢" if metrics.misconceptions_active == 0 else "ğŸŸ¡" if metrics.misconceptions_active <= 3 else "ğŸ”´"
    table.add_row(
        "Active Misconceptions",
        str(metrics.misconceptions_active),
        "0",
        misc_status
    )
    
    console.print(table)
    
    # Show progress bars for key metrics
    console.print("\n[bold]Progress Indicators:[/bold]\n")
    
    with Progress() as progress:
        # Retrieval progress
        retrieval_task = progress.add_task(
            "[cyan]Retrieval Rate",
            total=100,
            completed=retrieval_score
        )
        
        # Card completion progress
        card_task = progress.add_task(
            "[cyan]Daily Cards",
            total=metrics.daily_review_throughput,
            completed=metrics.cards_completed_today
        )
        
        # Calibration progress
        cal_task = progress.add_task(
            "[cyan]Calibration",
            total=100,
            completed=metrics.avg_prediction_accuracy_7d
        )


@metrics_group.command(name="calculate")
@click.option("--type", "-t",
              type=click.Choice(["retrieval", "calibration", "debt", "all"]),
              default="all",
              help="Metric type to calculate")
@click.pass_context
def calculate_metrics(ctx: click.Context, type: str) -> None:
    """Recalculate metrics from session history.
    
    Updates:
    - 7-day rolling averages
    - Card debt ratios
    - Performance trends
    """
    console: Console = ctx.obj['console']
    state_manager = StateManager()
    
    coach_state = state_manager.load_coach_state()
    metrics = coach_state.performance_metrics
    
    console.print(f"[cyan]Calculating {type} metrics...[/cyan]")
    
    if type in ["retrieval", "all"]:
        # In full implementation, would scan session history
        # For now, simulate with slight adjustment
        old_retrieval = metrics.avg_retrieval_7d
        metrics.avg_retrieval_7d = (metrics.avg_retrieval_7d * 0.9 + 82)  # Simulated new data
        console.print(f"âœ“ Retrieval rate updated: {old_retrieval:.1f}% â†’ {metrics.avg_retrieval_7d:.1f}%")
    
    if type in ["calibration", "all"]:
        # Update calibration accuracy
        old_cal = metrics.avg_prediction_accuracy_7d
        metrics.avg_prediction_accuracy_7d = (metrics.avg_prediction_accuracy_7d * 0.9 + 75)
        console.print(f"âœ“ Calibration updated: {old_cal:.0f}% â†’ {metrics.avg_prediction_accuracy_7d:.0f}%")
    
    if type in ["debt", "all"]:
        # Calculate card debt
        if metrics.daily_review_throughput > 0:
            metrics.current_card_debt_ratio = metrics.cards_due / metrics.daily_review_throughput
        console.print(f"âœ“ Card debt ratio: {metrics.current_card_debt_ratio:.1f}x")
    
    state_manager.save_coach_state(coach_state)
    console.print("\n[green]âœ“ Metrics updated successfully![/green]")


@metrics_group.command(name="trends")
@click.option("--days", "-d", type=int, default=7, help="Days to analyze")
@click.pass_context
def show_trends(ctx: click.Context, days: int) -> None:
    """Show performance trends over time.
    
    Analyzes:
    - Retrieval rate changes
    - Card completion patterns
    - Session consistency
    - Learning velocity
    """
    console: Console = ctx.obj['console']
    state_manager = StateManager()
    
    coach_state = state_manager.load_coach_state()
    metrics = coach_state.performance_metrics
    
    console.print(
        Panel(
            f"[bold cyan]ğŸ“ˆ {days}-Day Trends[/bold cyan]\n\n"
            f"[cyan]Retrieval Rate:[/cyan]\n"
            f"  Current: {metrics.avg_retrieval_7d:.1f}%\n"
            f"  Trend: {'ğŸ“ˆ Improving' if metrics.avg_retrieval_7d > 80 else 'ğŸ“‰ Declining' if metrics.avg_retrieval_7d < 75 else 'â¡ï¸ Stable'}\n\n"
            f"[cyan]Card Throughput:[/cyan]\n"
            f"  Daily: {metrics.daily_review_throughput}\n"
            f"  Completed: {metrics.cards_completed_today}\n"
            f"  Efficiency: {(metrics.cards_completed_today / metrics.daily_review_throughput * 100) if metrics.daily_review_throughput > 0 else 0:.0f}%\n\n"
            f"[cyan]Knowledge Creation:[/cyan]\n"
            f"  Notes/week: {metrics.total_permanent_notes / max(1, days/7):.1f}\n"
            f"  Cards/session: {metrics.total_flashcards / max(1, sum(1 for b in coach_state.active_books if b.sessions_completed > 0)):.1f}\n\n"
            f"[cyan]Learning Health:[/cyan]\n"
            f"  Misconceptions: {metrics.misconceptions_active} active, {metrics.misconceptions_resolved} resolved\n"
            f"  Resolution rate: {(metrics.misconceptions_resolved / max(1, metrics.misconceptions_active + metrics.misconceptions_resolved) * 100):.0f}%",
            style="cyan"
        )
    )


@metrics_group.command(name="report")
@click.option("--format", "-f",
              type=click.Choice(["summary", "detailed", "csv"]),
              default="summary",
              help="Report format")
@click.option("--output", "-o", help="Output file path")
@click.pass_context
def generate_report(ctx: click.Context, format: str, output: Optional[str]) -> None:
    """Generate a metrics report.
    
    Formats:
    - Summary: Key metrics and status
    - Detailed: Full analysis with recommendations
    - CSV: Export for external analysis
    """
    console: Console = ctx.obj['console']
    state_manager = StateManager()
    
    coach_state = state_manager.load_coach_state()
    metrics = coach_state.performance_metrics
    governance = coach_state.governance_status
    
    if format == "summary":
        report = f"""# OSL Learning Report
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}

## Key Metrics
- Retrieval Rate: {metrics.avg_retrieval_7d:.1f}%
- Card Debt: {metrics.current_card_debt_ratio:.1f}x
- Calibration: {metrics.avg_prediction_accuracy_7d:.0f}%
- Active Books: {len(coach_state.active_books)}

## Governance Status
- Calibration Gate: {governance.calibration_gate}
- Card Debt Gate: {governance.card_debt_gate}
- Transfer Gate: {governance.transfer_gate}
- Overall: {governance.overall_state}

## Progress
- Total Notes: {metrics.total_permanent_notes}
- Total Cards: {metrics.total_flashcards}
- Misconceptions Resolved: {metrics.misconceptions_resolved}
"""
    
    elif format == "detailed":
        report = f"""# OSL Detailed Learning Analysis
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}

## Executive Summary
Learning system is in {governance.overall_state} state with {sum(1 for g in [governance.calibration_gate, governance.card_debt_gate] if g == 'passing')}/3 gates passing.

## Performance Metrics

### Retrieval Practice
- 7-day average: {metrics.avg_retrieval_7d:.1f}%
- Target range: {coach_state.governance_thresholds.calibration_gate.min}-{coach_state.governance_thresholds.calibration_gate.max}%
- Status: {'âœ“ Within target' if metrics.avg_retrieval_7d >= coach_state.governance_thresholds.calibration_gate.min else 'âš ï¸ Below threshold'}

### Spaced Repetition
- Cards due: {metrics.cards_due}
- Daily throughput: {metrics.daily_review_throughput}
- Debt ratio: {metrics.current_card_debt_ratio:.1f}x
- Debt threshold: {coach_state.governance_thresholds.card_debt_multiplier.current}x

### Knowledge Construction
- Permanent notes: {metrics.total_permanent_notes}
- Flashcards: {metrics.total_flashcards}
- Average cards/session: {metrics.total_flashcards / max(1, sum(b.sessions_completed for b in coach_state.active_books)):.1f}

### Error Correction
- Active misconceptions: {metrics.misconceptions_active}
- Resolved: {metrics.misconceptions_resolved}
- Resolution rate: {(metrics.misconceptions_resolved / max(1, metrics.misconceptions_active + metrics.misconceptions_resolved) * 100):.0f}%

## Recommendations
"""
        
        # Add recommendations based on metrics
        if metrics.avg_retrieval_7d < coach_state.governance_thresholds.calibration_gate.min:
            report += "- Focus on retrieval practice quality\n"
        if metrics.current_card_debt_ratio > coach_state.governance_thresholds.card_debt_multiplier.current:
            report += "- Reduce new card creation temporarily\n"
        if metrics.interleaving_sessions_week < 1:
            report += "- Schedule interleaving sessions\n"
        if metrics.misconceptions_active > 3:
            report += "- Prioritize misconception resolution\n"
    
    else:  # CSV format
        report = f"""metric,value,target,status
retrieval_rate,{metrics.avg_retrieval_7d:.1f},{coach_state.governance_thresholds.calibration_gate.min},{'passing' if metrics.avg_retrieval_7d >= coach_state.governance_thresholds.calibration_gate.min else 'failing'}
card_debt_ratio,{metrics.current_card_debt_ratio:.1f},{coach_state.governance_thresholds.card_debt_multiplier.current},{'passing' if metrics.current_card_debt_ratio <= coach_state.governance_thresholds.card_debt_multiplier.current else 'failing'}
calibration_accuracy,{metrics.avg_prediction_accuracy_7d:.0f},75,{'passing' if metrics.avg_prediction_accuracy_7d >= 75 else 'failing'}
permanent_notes,{metrics.total_permanent_notes},,
flashcards,{metrics.total_flashcards},,
misconceptions_active,{metrics.misconceptions_active},0,
misconceptions_resolved,{metrics.misconceptions_resolved},,
"""
    
    if output:
        with open(output, 'w') as f:
            f.write(report)
        console.print(f"[green]âœ“ Report saved to: {output}[/green]")
    else:
        console.print(report)